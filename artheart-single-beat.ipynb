{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Group 1/6.csv\n",
      "Data/Group 1/40.csv\n",
      "Data/Group 1/7.csv\n",
      "Data/Group 1/5.csv\n",
      "Data/Group 1/4.csv\n",
      "Data/Group 1/1.csv\n",
      "Data/Group 1/3.csv\n",
      "Data/Group 1/2.csv\n",
      "Data/Group 1/37.csv\n",
      "Data/Group 1/23.csv\n",
      "Data/Group 1/22.csv\n",
      "Data/Group 1/36.csv\n",
      "Data/Group 1/20.csv\n",
      "Data/Group 1/34.csv\n",
      "Data/Group 1/35.csv\n",
      "Data/Group 1/21.csv\n",
      "Data/Group 1/25.csv\n",
      "Data/Group 1/31.csv\n",
      "Data/Group 1/19.csv\n",
      "Data/Group 1/18.csv\n",
      "Data/Group 1/30.csv\n",
      "Data/Group 1/24.csv\n",
      "Data/Group 1/32.csv\n",
      "Data/Group 1/26.csv\n",
      "Data/Group 1/27.csv\n",
      "Data/Group 1/33.csv\n",
      "Data/Group 1/16.csv\n",
      "Data/Group 1/17.csv\n",
      "Data/Group 1/29.csv\n",
      "Data/Group 1/15.csv\n",
      "Data/Group 1/14.csv\n",
      "Data/Group 1/28.csv\n",
      "Data/Group 1/10.csv\n",
      "Data/Group 1/38.csv\n",
      "Data/Group 1/39.csv\n",
      "Data/Group 1/11.csv\n",
      "Data/Group 1/13.csv\n",
      "Data/Group 1/12.csv\n",
      "Data/Group 1/9.csv\n",
      "Data/Group 1/8.csv\n",
      "Data/Group 2/6.csv\n",
      "Data/Group 2/40.csv\n",
      "Data/Group 2/7.csv\n",
      "Data/Group 2/5.csv\n",
      "Data/Group 2/4.csv\n",
      "Data/Group 2/42.csv\n",
      "Data/Group 2/46.csv\n",
      "Data/Group 2/1.csv\n",
      "Data/Group 2/47.csv\n",
      "Data/Group 2/3.csv\n",
      "Data/Group 2/44.csv\n",
      "Data/Group 2/2.csv\n",
      "Data/Group 2/37.csv\n",
      "Data/Group 2/22.csv\n",
      "Data/Group 2/20.csv\n",
      "Data/Group 2/34.csv\n",
      "Data/Group 2/35.csv\n",
      "Data/Group 2/21.csv\n",
      "Data/Group 2/25.csv\n",
      "Data/Group 2/31.csv\n",
      "Data/Group 2/19.csv\n",
      "Data/Group 2/18.csv\n",
      "Data/Group 2/24.csv\n",
      "Data/Group 2/32.csv\n",
      "Data/Group 2/27.csv\n",
      "Data/Group 2/33.csv\n",
      "Data/Group 2/16.csv\n",
      "Data/Group 2/17.csv\n",
      "Data/Group 2/29.csv\n",
      "Data/Group 2/14.csv\n",
      "Data/Group 2/28.csv\n",
      "Data/Group 2/10.csv\n",
      "Data/Group 2/38.csv\n",
      "Data/Group 2/39.csv\n",
      "Data/Group 2/11.csv\n",
      "Data/Group 2/13.csv\n",
      "Data/Group 2/48.csv\n",
      "Data/Group 2/9.csv\n",
      "Data/Group 2/8.csv\n",
      "Data/Group 3/6.csv\n",
      "Data/Group 3/7.csv\n",
      "Data/Group 3/5.csv\n",
      "Data/Group 3/4.csv\n",
      "Data/Group 3/1.csv\n",
      "Data/Group 3/3.csv\n",
      "Data/Group 3/2.csv\n",
      "Data/Group 3/37.csv\n",
      "Data/Group 3/22.csv\n",
      "Data/Group 3/36.csv\n",
      "Data/Group 3/20.csv\n",
      "Data/Group 3/34.csv\n",
      "Data/Group 3/35.csv\n",
      "Data/Group 3/21.csv\n",
      "Data/Group 3/25.csv\n",
      "Data/Group 3/31.csv\n",
      "Data/Group 3/19.csv\n",
      "Data/Group 3/30.csv\n",
      "Data/Group 3/24.csv\n",
      "Data/Group 3/32.csv\n",
      "Data/Group 3/26.csv\n",
      "Data/Group 3/27.csv\n",
      "Data/Group 3/16.csv\n",
      "Data/Group 3/17.csv\n",
      "Data/Group 3/29.csv\n",
      "Data/Group 3/14.csv\n",
      "Data/Group 3/28.csv\n",
      "Data/Group 3/10.csv\n",
      "Data/Group 3/38.csv\n",
      "Data/Group 3/13.csv\n",
      "Data/Group 3/9.csv\n",
      "Data/Group 3/8.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data(dir):\n",
    "    data = []\n",
    "    order = []\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(\".csv\"):\n",
    "            print(os.path.join(dir, file))\n",
    "            df = pd.read_csv(os.path.join(dir, file),on_bad_lines='skip')\n",
    "            if not df.empty:\n",
    "                order.append(int(file[:-4]))\n",
    "                data.append(df[\"DATA\"])\n",
    "    return data, order\n",
    "\n",
    "\n",
    "try:\n",
    "    Group1, Group1_order = load_data(\"/mnt/ArtHeart/Data/Group 1\")\n",
    "    Group2, Group2_order = load_data(\"/mnt/ArtHeart/Data/Group 2\")\n",
    "    Group3, Group3_order = load_data(\"/mnt/ArtHeart/Data/Group 3\")\n",
    "except:\n",
    "    try:\n",
    "        Group1, Group1_order = load_data(\"Data/Group 1\")\n",
    "        Group2, Group2_order = load_data(\"Data/Group 2\")\n",
    "        Group3, Group3_order = load_data(\"Data/Group 3\")\n",
    "    except:\n",
    "        Group1, Group1_order = load_data(\"W:\\PhD\\ArtHeart\\Data\\Group 1\")\n",
    "        Group2, Group2_order = load_data(\"W:\\PhD\\ArtHeart\\Data\\Group 2\")\n",
    "        Group3, Group3_order = load_data(\"W:\\PhD\\ArtHeart\\Data\\Group 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ArtHeart/Data/Group 1 Scores.xlsx\n",
      "/mnt/ArtHeart/Data/\n",
      "W:\\PhD\\ArtHeart\\Data\\Group 1 Scores.xlsx\n",
      "W:\\PhD\\ArtHeart\\Data\\\n",
      "Data/Group 1 Scores.xlsx\n",
      "Data/\n",
      "Data/Group 2 Scores.xlsx\n",
      "Data/\n",
      "Data/Group 3 Scores.csv\n",
      "Data\n"
     ]
    }
   ],
   "source": [
    "Group1_scores = []\n",
    "Group2_scores = []\n",
    "Group3_scores = []\n",
    "\n",
    "def emotion_definer(emotions):\n",
    "    emotions = emotions.split(\";\")\n",
    "    emotions = [x.strip(' ') for x in emotions]\n",
    "    emotion_score = []\n",
    "    for emotion in emotions:\n",
    "        emotion = emotion.lower()\n",
    "        if emotion == 'happy' or emotion == 'immersed' or emotion == 'excited' or emotion == 'hyped up' or emotion == 'hypedup' or emotion == 'delighted':\n",
    "            emotion_score.append(2)\n",
    "        elif emotion == 'sad' or emotion == 'angry' or ('frustrated' in emotion) or ('annoyed' in emotion) or emotion == 'bored' or emotion == 'sleepy' or emotion == 'tired' or emotion == 'nervous' or ('anxious' in emotion) or emotion == 'scared':\n",
    "            emotion_score.append(0)\n",
    "        elif emotion == 'tense' or emotion == 'confused' or  emotion == 'relaxed' or emotion == 'intrigued' or emotion == 'interest' or emotion == 'content' or emotion == 'calm' or emotion == 'mellow' or emotion == 'alright' or emotion == 'fine' or emotion == 'other':\n",
    "            emotion_score.append(1)\n",
    "\n",
    "    if not emotion_score:\n",
    "        emotion_score.append(0)\n",
    "    \n",
    "    emotion = round(np.mean(emotion_score))\n",
    "    \n",
    "    if emotion is np.nan:\n",
    "        emotion = 0\n",
    "\n",
    "    return emotion\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "def load_Scores(location):\n",
    "    print(location)\n",
    "    folder = location[:-19]\n",
    "    print(folder)\n",
    "    var = os.listdir(folder)\n",
    "    group = ''\n",
    "\n",
    "    if \"Group 1\" in location:\n",
    "        group = \"Group 1\"\n",
    "    elif \"Group 2\" in location:\n",
    "        group = \"Group 2\"\n",
    "    elif \"Group 3\" in location:\n",
    "        group = \"Group 3\"\n",
    "        folder = folder + \"/\"\n",
    "\n",
    "    for file in var:\n",
    "        if group in file:\n",
    "            if \"xlsx\" in file:\n",
    "                location = folder + file\n",
    "                data = pd.read_excel(location)\n",
    "            elif \"csv\" in file:\n",
    "                location = folder + file\n",
    "                data = pd.read_csv(location)\n",
    "\n",
    "\n",
    "    if \"How would you rate this performance?\" in data.columns:\n",
    "        order = data[\"Watch ID\"]\n",
    "        scores = data[\"How would you rate this performance?\"]\n",
    "    elif \"How did you rate the performance?\" in data.columns:\n",
    "        order = data[\"Watch ID\"]\n",
    "        scores  = data[\"How did you rate the performance?\"]\n",
    "    elif \"How would you rate this performance?（10 is the best）\" in data.columns:\n",
    "        order = data[\"ID\"]\n",
    "        scores  = data[\"How would you rate this performance?（10 is the best）\"]\n",
    "\n",
    "    if \"How would you describe your feelings through the performance?\" in data.columns:\n",
    "        emotions = data[\"How would you describe your feelings through the performance?\"]\n",
    "    elif \"How do you describe your feeling during the programme? You may make multiple choices.\\n\" in data.columns:\n",
    "        emotions = data[\"How do you describe your feeling during the programme? You may make multiple choices.\\n\"]\n",
    "        \n",
    "    emotions = emotions.apply(emotion_definer)\n",
    "        \n",
    "    return scores, order, emotions\n",
    "\n",
    "\n",
    "def match_scores_to_data(scores, scores_order, emotions, data, data_order):\n",
    "    matched_scores = []\n",
    "    matched_data = []\n",
    "    matched_emotions = []\n",
    "\n",
    "    # Zip the scores and order and the data and data order\n",
    "    scores_zip = zip(scores_order, scores, emotions)\n",
    "    data_zip = zip(data_order, data)\n",
    "\n",
    "    # Sort the zipped lists by order\n",
    "    scores_zip = sorted(scores_zip, key=lambda x: x[0])\n",
    "    data_zip = sorted(data_zip, key=lambda x: x[0])\n",
    "\n",
    "    # Unzip the sorted lists\n",
    "    sorted_scores_order, sorted_scores, sorted_emotions = zip(*scores_zip)\n",
    "    sorted_data_order, sorted_data = zip(*data_zip)\n",
    "\n",
    "    # Match the scores to the data using the order of each\n",
    "    for i in range(min(len(sorted_scores_order), len(sorted_data_order))):\n",
    "        if sorted_scores_order[i] == sorted_data_order[i]:\n",
    "            matched_scores.append(sorted_scores[i])\n",
    "            matched_data.append(sorted_data[i])\n",
    "            matched_emotions.append(emotions[i])\n",
    "    return matched_scores, matched_data, matched_emotions\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    Group1_scores, Group1_scores_order, Group1_emotions = load_Scores(\"/mnt/ArtHeart/Data/Group 1 Scores.xlsx\")\n",
    "    Group2_scores,Group2_scores_order, Group2_emotions = load_Scores(\"/mnt/ArtHeart/Data/Group 2 Scores.xlsx\")\n",
    "    Group3_scores,Group3_scores_order, Group3_emotions = load_Scores(\"/mnt/ArtHeart/Data/Group 3 Scores.csv\")\n",
    "except:\n",
    "    try:\n",
    "        Group1_scores, Group1_scores_order, Group1_emotions = load_Scores(\"W:\\PhD\\ArtHeart\\Data\\Group 1 Scores.xlsx\")\n",
    "        Group2_scores,Group2_scores_order, Group2_emotions = load_Scores(\"W:\\PhD\\ArtHeart\\Data\\Group 2 Scores.xlsx\")\n",
    "        Group3_scores,Group3_scores_order, Group3_emotions = load_Scores(\"W:\\PhD\\ArtHeart\\Data\\Group 3 Scores.csv\")\n",
    "\n",
    "    except:\n",
    "        Group1_scores, Group1_scores_order, Group1_emotions = load_Scores(\"Data/Group 1 Scores.xlsx\")\n",
    "        Group2_scores,Group2_scores_order, Group2_emotions = load_Scores(\"Data/Group 2 Scores.xlsx\")\n",
    "        Group3_scores,Group3_scores_order, Group3_emotions = load_Scores(\"Data/Group 3 Scores.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Group1_scores, Group1_processed, Group1_emotions = match_scores_to_data(Group1_scores, Group1_scores_order, Group1_emotions, Group1_processed, Group1_order)\n",
    "Group2_scores, Group2_processed, Group2_emotions = match_scores_to_data(Group2_scores, Group2_scores_order, Group2_emotions, Group2, Group2_order)\n",
    "Group3_scores, Group3_processed, Group3_emotions = match_scores_to_data(Group3_scores, Group3_scores_order, Group3_emotions, Group3, Group3_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 2:  30 30 30\n",
      "Group 3:  30 30 30\n",
      "0         1234\n",
      "1         1233\n",
      "2         1233\n",
      "3         1233\n",
      "4         1233\n",
      "          ... \n",
      "127579      59\n",
      "127580      59\n",
      "127581      59\n",
      "127582      59\n",
      "127583      59\n",
      "Name: DATA, Length: 127584, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Group 2: \", len(Group2_scores), len(Group2_processed), len(Group2_emotions))\n",
    "print(\"Group 3: \", len(Group3_scores), len(Group3_processed), len(Group3_emotions))\n",
    "\n",
    "print(Group2_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "[1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 2, 2, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(Group2_emotions)\n",
    "print(Group3_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 129624, 1) (60,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import one_hot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = []\n",
    "X.extend(Group2_processed)\n",
    "X.extend(Group3_processed)\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = np.array(X[i]).reshape(-1,1)\n",
    "    X[i] = scale.fit_transform(X[i])\n",
    "\n",
    "max_len = 0\n",
    "for seq in X:\n",
    "    if len(seq) > max_len:\n",
    "        max_len = len(seq)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq_len = len(X[i])\n",
    "    if seq_len < max_len:\n",
    "        padding_len = max_len - seq_len\n",
    "        padding = [-10] * padding_len\n",
    "        series = X[i].flatten()\n",
    "        series = np.concatenate((series, padding), axis=0)\n",
    "        X[i] = series.flatten()\n",
    "    else:\n",
    "        X[i] = X[i].flatten()\n",
    "\n",
    "y = []\n",
    "y.extend(Group2_emotions)\n",
    "y.extend(Group3_emotions)\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(X).reshape(-1, max_len, 1)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:12:48.044833: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-06-20 13:12:48.044872: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-06-20 13:12:48.044915: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-06-20 13:12:48.045541: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-20 13:12:48.045898: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = one_hot(y_train, 3)\n",
    "y_test = one_hot(y_test, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Masking(mask_value=-10, input_shape=(None, 1)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, None, 1)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 64)          16896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 64)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50115 (195.76 KB)\n",
      "Trainable params: 50115 (195.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 13:12:50.667621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 13:12:51.075457: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 13:12:58.063125: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2023-06-20 13:12:58.104210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-20 13:13:06.731310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1, steps_per_epoch=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
